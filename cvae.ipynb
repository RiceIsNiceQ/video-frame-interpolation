{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfNT-mlFwxVM",
    "tags": []
   },
   "source": [
    "# Convolutional Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h",
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-JuIu2N_SQf"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-probability\n",
    "\n",
    "# to generate gifs\n",
    "!pip install imageio\n",
    "\n",
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import tensorflow_docs.vis.embed as embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBAL SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL\n",
    "EPOCHS = 20\n",
    "\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "LATENT_DIM_SIZE = 50\n",
    "EXAMPLE_COUNT_PREVIEW = 16\n",
    "\n",
    "# TRAINING PARAMETER\n",
    "TRAIN_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "TEST_SIZE = 10000\n",
    "\n",
    "# WEIGHT LOADING / SAVING\n",
    "TRAIN_WEIGHTS = True\n",
    "LOAD_WEIGHTS = True\n",
    "LOAD_FROM_EPOCHS = 1\n",
    "LOAD_FROM_NAME = \"DEFAULT\"\n",
    "SAVE_TO_NAME = \"DEFAULT\"\n",
    "SAVE_INTERVAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHODS / CLASSES\n",
    "### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "    normalization_layer = layers.experimental.preprocessing.Rescaling(scale= 1./255)\n",
    "    return images.map(lambda x: normalization_layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, LATENT_DIM_SIZE):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.LATENT_DIM_SIZE = LATENT_DIM_SIZE\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(256, 256, 3)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(LATENT_DIM_SIZE + LATENT_DIM_SIZE),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(LATENT_DIM_SIZE,)),\n",
    "            tf.keras.layers.Dense(units=8*8*64, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(8, 8, 64)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=3, kernel_size=3, strides=2, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.LATENT_DIM_SIZE))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELPER LOSS COMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE HELPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "  mean, logvar = model.encode(test_sample)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  print(z[0])\n",
    "  predictions = model.sample(z)\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  '''for i in range(predictions.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(predictions[i, :, :, 0])\n",
    "    plt.axis('off')'''\n",
    "  for i in range(predictions.shape[0]):\n",
    "    ax = fig.add_subplot(4, 4, i+1)\n",
    "    ax.axis('off')\n",
    "    pred = predictions[i, :, :, :] * 255\n",
    "    pred = np.array(pred)  \n",
    "    pred = pred.astype(np.uint8)\n",
    "    \n",
    "    ax.imshow(pred)\n",
    "\n",
    "  # tight_layout minimizes the overlap between 2 sub-plots\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n",
    "\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
    "\n",
    "\n",
    "def plot_latent_images(model, n, digit_size=256):\n",
    "  \"\"\"Plots n x n digit images decoded from the latent space.\"\"\"\n",
    "\n",
    "  norm = tfp.distributions.Normal(0, 1)\n",
    "  grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  image_width = digit_size*n\n",
    "  image_height = image_width\n",
    "  image = np.zeros((image_height, image_width, 3))\n",
    "\n",
    "  for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "      z = np.full((1, 50), xi)\n",
    "      x_decoded = model.sample(z)\n",
    "      #digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\n",
    "      digit = tf.reshape(x_decoded[0], (digit_size, digit_size, 3))\n",
    "      image[i * digit_size: (i + 1) * digit_size,\n",
    "            j * digit_size: (j + 1) * digit_size] = digit.numpy()\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  plt.imshow(image)\n",
    "  plt.axis('Off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT\n",
    "## LOAD AND PRERPOCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4fYMGxGhrna"
   },
   "outputs": [],
   "source": [
    "if TRAIN_WEIGHTS:\n",
    "\ttrain_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "\t\t  'data/cartoonset10k',\n",
    "\t\t  image_size=(256, 256),\n",
    "\t\t  batch_size=BATCH_SIZE,\n",
    "\t\t  label_mode=None)\n",
    "\ttest_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "\t\t  'data/cartoonsetTest',\n",
    "\t\t  image_size=(256, 256),\n",
    "\t\t  batch_size=BATCH_SIZE,\n",
    "\t\t  label_mode=None)\n",
    "\t\n",
    "\ttrain_dataset = preprocess_images(train_images)\n",
    "\ttest_dataset = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE AND PRINT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CVAE(LATENT_DIM_SIZE)\n",
    "model.encoder.summary()\n",
    "model.decoder.summary()\n",
    "\n",
    "starting_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD EXISTING WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_WEIGHTS:\n",
    "    model.load_weights(\"./model_weights/model_weights_epochs_\" + str(LOAD_FROM_EPOCHS) + \"_latentDimSize_\" + str(LATENT_DIM_SIZE) + \"_\" + LOAD_FROM_NAME)\n",
    "    starting_epoch = LOAD_FROM_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSURE ENOUGH IMAGES IN BATCH FOR EXAMPLE PREVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swCyrbqQQ-Ri"
   },
   "outputs": [],
   "source": [
    "assert BATCH_SIZE >= EXAMPLE_COUNT_PREVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a sample of the test set for generating output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "if (TRAIN_WEIGHTS):\n",
    "  for test_batch in test_dataset.take(1):\n",
    "    test_sample = test_batch[0:EXAMPLE_COUNT_PREVIEW, :, :, :]\n",
    "    generate_and_save_images(model, 0, test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (TRAIN_WEIGHTS):\n",
    "  for epoch in range(1 + starting_epoch, EPOCHS_TO_LEARN + starting_epoch + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train_dataset:\n",
    "      train_step(model, train_x, optimizer)\n",
    "    end_time = time.time()\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for test_x in test_dataset:\n",
    "      loss(compute_loss(model, test_x))\n",
    "    elbo = -loss.result()\n",
    "    display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "          .format(epoch, elbo, end_time - start_time))\n",
    "    generate_and_save_images(model, epoch, test_sample)\n",
    "    \n",
    "    # SAVE WEIGHTS IF INTERVAL IS REACHED\n",
    "    if epoch % SAVE_INTERVAL == 0:\n",
    "      model.save_weights(\"./model_weights/model_weights_epochs_\" + str(epoch) + \"_latentDimSize_\" + str(LATENT_DIM_SIZE) + \"_\" + SAVE_TO_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "## Display a generated image from the last training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5x3q9_Oe5q0A"
   },
   "outputs": [],
   "source": [
    "plt.imshow(display_image(starting_epoch + EPOCHS_TO_LEARN))\n",
    "plt.axis('off')  # Display images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NywiH3nL8guF"
   },
   "source": [
    "## Display an animated GIF of all the saved images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGKQgENQ8lEI"
   },
   "outputs": [],
   "source": [
    "anim_file = 'cvae.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeunRU6TSumT"
   },
   "source": [
    "## Display a 2D manifold of digits from the latent space\n",
    "\n",
    "Running the code below will show a continuous distribution of the different digit classes, with each digit morphing into another across the 2D latent space. Use [TensorFlow Probability](https://www.tensorflow.org/probability) to generate a standard normal distribution for the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-ZG69QCZnGY"
   },
   "outputs": [],
   "source": [
    "plot_latent_images(model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING TO GENERATE THE MIDDLE OF TWO LATENT VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector_1 = np.array([[1.02536201e+00,-2.94102907e-01,1.64790154e+00,5.03614378e+00\n",
    ",-1.36321330e+00,2.76926208e+00,2.62857294e+00,-2.85130680e-01\n",
    ",5.45753288e+00,-5.88454783e-01,-3.84467030e+00,-1.64728820e+00\n",
    ",3.35834241e+00,2.38665032e+00,4.59312290e-01,4.03293180e+00\n",
    ",-2.09909391e+00,1.86549067e+00,2.92326331e+00,1.43550122e+00\n",
    ",1.09568393e+00,6.20597601e-01,1.06155002e+00,-1.24831879e+00\n",
    ",2.43738413e+00,2.81176567e+00,-2.76000261e+00,4.34566402e+00\n",
    ",2.15681386e+00,3.06898761e+00,1.10142100e+00,-9.84009326e-01\n",
    ",-2.62474108e+00,5.17143011e-01,-2.81945992e+00,-1.52866042e+00\n",
    ",-1.58329403e+00,5.65068102e+00,2.48366165e+00,9.66846406e-01\n",
    ",2.71668248e-02,-3.77461410e+00,-1.64389789e+00,-1.25075352e+00\n",
    ",1.16503072e+00,1.71287203e+00,8.78006816e-01,3.15090984e-01\n",
    ",3.11333919e+00,3.72572333e-01]])\n",
    "latent_vector_2 = np.array([[3.11055994e+00,2.77322316e+00,-2.35439253e+00,2.41457534e+00\n",
    ",1.65251720e+00,-1.03567481e+00,2.88300347e+00,-1.77975857e+00\n",
    ",2.07237649e+00,1.63250697e+00,-2.08729815e+00,-2.19439089e-01\n",
    ",3.46109211e-01,5.82732618e-01,9.14461792e-01,-2.96111321e+00\n",
    ",4.46764648e-01,3.61388826e+00,5.34072161e+00,2.61096501e+00\n",
    ",2.48561978e+00,-2.73324752e+00,-2.11599898e+00,-1.75424963e-02\n",
    ",-1.14708841e+00,-4.10792542e+00,-3.23143697e+00,2.21529269e+00\n",
    ",2.15655327e+00,-3.28153896e+00,2.36182594e+00,-9.16283727e-01\n",
    ",-1.41235209e+00,-6.11949027e-01,-8.87000144e-01,-2.13673401e+00\n",
    ",-1.98448431e+00,9.77515399e-01,2.29458719e-01,4.20075655e-02\n",
    ",7.69120634e-01,2.98409581e+00,1.02206600e+00,2.46658057e-01\n",
    ",-3.60222936e-01,1.56427526e+00,-1.47916779e-01,2.49203157e+00\n",
    ",1.60648060e+00,1.21420026e+00]])\n",
    "random_vector = np.random.normal(0., 0.75, size=(1, 50))\n",
    "random_vector_2 = (np.random.rand(1, 50) - 0.5) * 4\n",
    "print(random_vector_2)\n",
    "combined_vector = (latent_vector_1 * 0.2 + latent_vector_2 * 0.8)\n",
    "print(latent_vector_1)\n",
    "pred = model.decode(combined_vector, True)[0, :, :, :] * 255\n",
    "pred = np.array(pred)  \n",
    "pred = pred.astype(np.uint8)\n",
    "    \n",
    "plt.imshow(pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "toc_visible": true
  },
  "interpreter": {
   "hash": "f8370c5edc7826c41f4553f23b77bdb16aadbbe7ab4c8dea439685e957def059"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
